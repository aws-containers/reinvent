# CNS419 | Optimize GenAI inference and model performance on Amazon EKS 

Explore proven strategies for optimizing LLM loading times and inference performance on Amazon EKS. This chalk talk dives into critical infrastructure decisions, comparing storage solutions such as Amazon S3, EFS/FSx, and EBS for minimal model loading latency. Learn practical patterns for distributed inference, efficient GPU scheduling, and networking optimizations for cross-AZ communication. We'll demonstrate how to leverage EKS features and open-source tools to build high-performance GenAI infrastructure. Join us to discover best practices for architecting production-ready LLM deployments that balance performance, cost, and operational efficiency.

## Session Resources 

